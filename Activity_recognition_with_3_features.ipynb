{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Activity recognition with 3 features",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ivan-Nebogatikov/HumanActivityRecognition/blob/master/Activity_recognition_with_3_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CT1N3WYqAqm",
        "colab_type": "code",
        "outputId": "9cafa6e6-0a69-4ca9-adb4-4c2b3402e97f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "features = pd.read_csv('/final_ecg_data.csv')\n",
        "features = features[features['ECG'] > 0.]\n",
        "activities = list(sorted(set(features['activity'])))\n",
        "print(\"Activities:\", activities)\n",
        "#features['activity'] = list(map(lambda x: activities.index(x), features['activity']))\n",
        "features = features[features['activity'] != 'down the stairs']\n",
        "features = features[features['activity'] != 'up the stairs']\n",
        "#print(features.head(5)) \n",
        "print('The shape of our features is:', features.shape)\n",
        "\n",
        "features.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Activities: ['down the stairs', 'inactive', 'run', 'up the stairs', 'walk']\n",
            "The shape of our features is: (87235, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ECG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>87235.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.056951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.040650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.032104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.043610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.085968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.124969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                ECG\n",
              "count  87235.000000\n",
              "mean       0.056951\n",
              "std        0.040650\n",
              "min        0.000031\n",
              "25%        0.032104\n",
              "50%        0.043610\n",
              "75%        0.085968\n",
              "max        0.124969"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFfsldsJq8s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "labels = np.array(features['activity']) # значения, которые надо будет предсказывать\n",
        "features= features.drop('activity', axis = 1)\n",
        "feature_list = list(features.columns)\n",
        "features = np.array(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTleY1bMcZ9s",
        "colab_type": "text"
      },
      "source": [
        "Разделяем на обучающую и тестовую выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7aQurwHrP21",
        "colab_type": "code",
        "outputId": "4199723a-4d14-481c-ae8c-07723435d4a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.15, random_state = 543)\n",
        "print('Training Features Shape:', train_features.shape)\n",
        "print('Testing Features Shape:', test_features.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Features Shape: (74149, 1)\n",
            "Testing Features Shape: (13086, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oyIIitbBHVT",
        "colab_type": "text"
      },
      "source": [
        "Строим случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRjrbpcXrWBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators = 100, random_state = 1) # Классификатор с 100 деревьями\n",
        "rf.fit(train_features, train_labels);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMmFtqIMPfji",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Вспомогательная функция для построения таблицы с AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TfTT2qYTZbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import interp\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "def class_report(y_true, y_pred, y_score=None, average='micro'):\n",
        "    if y_true.shape != y_pred.shape:\n",
        "        print(\"Error! y_true %s is not the same shape as y_pred %s\" % (\n",
        "              y_true.shape,\n",
        "              y_pred.shape)\n",
        "        )\n",
        "        return\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "\n",
        "    lb = LabelBinarizer()\n",
        "\n",
        "    if len(y_true.shape) == 1:\n",
        "        lb.fit(y_true)\n",
        "\n",
        "    #Value counts of predictions\n",
        "    labels, cnt = np.unique(\n",
        "        y_pred,\n",
        "        return_counts=True)\n",
        "    n_classes = 5\n",
        "    pred_cnt = pd.Series(cnt, index=labels)\n",
        "\n",
        "    metrics_summary = precision_recall_fscore_support(\n",
        "            y_true=y_true,\n",
        "            y_pred=y_pred,\n",
        "            labels=labels)\n",
        "\n",
        "    avg = list(precision_recall_fscore_support(\n",
        "            y_true=y_true, \n",
        "            y_pred=y_pred,\n",
        "            average='weighted'))\n",
        "\n",
        "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
        "    class_report_df = pd.DataFrame(\n",
        "        list(metrics_summary),\n",
        "        index=metrics_sum_index,\n",
        "        columns=labels)\n",
        "\n",
        "    support = class_report_df.loc['support']\n",
        "    total = support.sum() \n",
        "    class_report_df['avg / total'] = avg[:-1] + [total]\n",
        "\n",
        "    class_report_df = class_report_df.T\n",
        "    class_report_df['pred'] = pred_cnt\n",
        "    class_report_df['pred'].iloc[-1] = total\n",
        "\n",
        "    if not (y_score is None):\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for label_it, label in enumerate(labels):\n",
        "            fpr[label], tpr[label], _ = roc_curve(\n",
        "                (y_true == label).astype(int), \n",
        "                y_score[:, label_it])\n",
        "\n",
        "            roc_auc[label] = auc(fpr[label], tpr[label])\n",
        "\n",
        "        if average == 'micro':\n",
        "            if n_classes <= 2:\n",
        "                fpr[\"avg / total\"], tpr[\"avg / total\"], _ = roc_curve(\n",
        "                    lb.transform(y_true).ravel(), \n",
        "                    y_score[:, 1].ravel())\n",
        "            else:\n",
        "                fpr[\"avg / total\"], tpr[\"avg / total\"], _ = roc_curve(\n",
        "                        lb.transform(y_true).ravel(), \n",
        "                        y_score.ravel())\n",
        "\n",
        "            roc_auc[\"avg / total\"] = auc(\n",
        "                fpr[\"avg / total\"], \n",
        "                tpr[\"avg / total\"])\n",
        "\n",
        "        elif average == 'macro':\n",
        "            # First aggregate all false positive rates\n",
        "            all_fpr = np.unique(np.concatenate([\n",
        "                fpr[i] for i in labels]\n",
        "            ))\n",
        "\n",
        "            # Then interpolate all ROC curves at this points\n",
        "            mean_tpr = np.zeros_like(all_fpr)\n",
        "            for i in labels:\n",
        "                mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "            # Finally average it and compute AUC\n",
        "            mean_tpr /= n_classes\n",
        "\n",
        "            fpr[\"macro\"] = all_fpr\n",
        "            tpr[\"macro\"] = mean_tpr\n",
        "\n",
        "            roc_auc[\"avg / total\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "        class_report_df['AUC'] = pd.Series(roc_auc)\n",
        "\n",
        "    print(class_report_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KcYDGvLQqP7",
        "colab_type": "text"
      },
      "source": [
        "Проверка на тестовых данных. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "viOLYP7qBpPZ",
        "outputId": "c876177c-c137-47ea-8a7d-b8689ecb580d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "\n",
        "predictions = list(rf.predict(test_features))\n",
        "pred_prob = rf.predict_proba(test_features)\n",
        "\n",
        "class_report(\n",
        "    y_true=test_labels, \n",
        "    y_pred=np.asarray(predictions), \n",
        "    y_score=pred_prob, average='micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6665902491211982\n",
            "             precision    recall  f1-score  support     pred       AUC\n",
            "inactive      0.616322  0.702295  0.656506   1656.0   1887.0  0.923518\n",
            "run           0.754862  0.641971  0.693855   5804.0   4936.0  0.802214\n",
            "walk          0.612167  0.681479  0.644966   5626.0   6263.0  0.724526\n",
            "avg / total   0.675982  0.666590  0.668110  13086.0  13086.0  0.845300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1SgPxyGBIbs",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "Сравним с методом опорных векторов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H3__XBdA6jO",
        "colab_type": "code",
        "outputId": "21b68031-2118-4cef-9016-e42cd4c74854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC(probability=True, class_weight='balanced')\n",
        "clf.fit(train_features, train_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slTMeYvwBDJ6",
        "colab_type": "code",
        "outputId": "45e128de-c851-4956-ce31-45c389793474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "predictions_svm = list(clf.predict(test_features))\n",
        "pred_prob_svm = clf.predict_proba(test_features)\n",
        "\n",
        "class_report(\n",
        "    y_true=test_labels, \n",
        "    y_pred=np.asarray(predictions_svm), \n",
        "    y_score=pred_prob_svm, average='micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6144734831117225\n",
            "             precision    recall  f1-score  support     pred       AUC\n",
            "inactive      0.386822  0.960749  0.551569   1656.0   4113.0  0.931720\n",
            "run           0.805437  0.617677  0.699171   5804.0   4451.0  0.816909\n",
            "walk          0.633569  0.509243  0.564643   5626.0   4522.0  0.730616\n",
            "avg / total   0.678572  0.614473  0.622656  13086.0  13086.0  0.851574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEZIo4iIQ16Y",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "Accuracy ниже, как и в случае с 5 классами.\n",
        "\n",
        "Точность для каждого класса выше, чем в методе SVM с 5 классами, поскольку классы больше различаются."
      ]
    }
  ]
}